{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebeb1024",
   "metadata": {},
   "source": [
    "Data exploration notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d523243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Locate project paths\n",
    "current_dir = os.path.dirname(os.path.abspath('1.0-data-exploration.ipynb')) # hadr/notebooks\n",
    "project_root = os.path.dirname(current_dir) # hadr\n",
    "raw_path = os.path.join(project_root, 'data', 'raw') # hadr/data/raw\n",
    "metadata_path = os.path.join(project_root, 'data', 'metadata') # hadr/data/metadata\n",
    "train_raw_path = os.path.join(raw_path, 'train.csv') # hadr/data/raw/train.csv\n",
    "test_raw_path = os.path.join(raw_path, 'test.csv') # hadr/data/raw/test.csv\n",
    "validation_raw_path = os.path.join(raw_path, 'validation.csv') # hadr/data/raw/validation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98387c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data csvs\n",
    "train_raw_data = pd.read_csv(train_raw_path)\n",
    "test_raw_data = pd.read_csv(test_raw_path)\n",
    "validation_raw_data = pd.read_csv(validation_raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f778291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>SOURCE_FILE</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_type_detail</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @violetposie: all of the above, in that ord...</td>\n",
       "      <td>0</td>\n",
       "      <td>150k_archiveteam</td>\n",
       "      <td>1.158830e+18</td>\n",
       "      <td>150k_archiveteam</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>target_zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"After China warns India, Baloch and Sindhi le...</td>\n",
       "      <td>1</td>\n",
       "      <td>200k_crisis_datasets_benchmarks_v1.0_informati...</td>\n",
       "      <td>7.702281e+17</td>\n",
       "      <td>crisis_consolidated_informativeness_filtered_l...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>informative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Sollygc very - but I managed to get a stubby ...</td>\n",
       "      <td>0</td>\n",
       "      <td>22k_ACL_ICWSM_2018_datasets_acl_icwsm_clean.csv</td>\n",
       "      <td>2.965785e+17</td>\n",
       "      <td>2013_Queensland_Floods_train.tsv</td>\n",
       "      <td>flood</td>\n",
       "      <td>flood</td>\n",
       "      <td>not_relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sneak attack from coast to do, I see, the dead...</td>\n",
       "      <td>0</td>\n",
       "      <td>12k_tweets.csv_kaggle2_clean.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12k_tweets.csv_kaggle2_clean.csv</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eastern and Western Attica declared in a state...</td>\n",
       "      <td>1</td>\n",
       "      <td>76k_HumAID_humaid_clean.csv</td>\n",
       "      <td>1.021746e+18</td>\n",
       "      <td>greece_wildfires_2018_train.tsv</td>\n",
       "      <td>fire</td>\n",
       "      <td>wild_fire</td>\n",
       "      <td>caution_and_advice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  RT @violetposie: all of the above, in that ord...       0   \n",
       "1  \"After China warns India, Baloch and Sindhi le...       1   \n",
       "2  @Sollygc very - but I managed to get a stubby ...       0   \n",
       "3  Sneak attack from coast to do, I see, the dead...       0   \n",
       "4  Eastern and Western Attica declared in a state...       1   \n",
       "\n",
       "                                         SOURCE_FILE      tweet_id  \\\n",
       "0                                   150k_archiveteam  1.158830e+18   \n",
       "1  200k_crisis_datasets_benchmarks_v1.0_informati...  7.702281e+17   \n",
       "2    22k_ACL_ICWSM_2018_datasets_acl_icwsm_clean.csv  2.965785e+17   \n",
       "3                   12k_tweets.csv_kaggle2_clean.csv           NaN   \n",
       "4                        76k_HumAID_humaid_clean.csv  1.021746e+18   \n",
       "\n",
       "                                            filename event_type  \\\n",
       "0                                   150k_archiveteam    unknown   \n",
       "1  crisis_consolidated_informativeness_filtered_l...    unknown   \n",
       "2                   2013_Queensland_Floods_train.tsv      flood   \n",
       "3                   12k_tweets.csv_kaggle2_clean.csv    unknown   \n",
       "4                    greece_wildfires_2018_train.tsv       fire   \n",
       "\n",
       "  event_type_detail               label  \n",
       "0           unknown         target_zero  \n",
       "1           unknown         informative  \n",
       "2             flood        not_relevant  \n",
       "3           unknown             unknown  \n",
       "4         wild_fire  caution_and_advice  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional: Inspect head of raw datasets\n",
    "train_raw_data.head()\n",
    "test_raw_data.head()\n",
    "validation_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a8dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji as ej\n",
    "\n",
    "# Handling tags and encoding emojis\n",
    "def encode_hashtags(text):\n",
    "    return re.sub(r'#(\\w+)', lambda m: f\" hashtag_{m.group(1)} \", text)\n",
    "\n",
    "def encode_mentions(text):\n",
    "    return re.sub(r'@(\\w+)', lambda m: f\" mention_{m.group(1)} \", text)\n",
    "\n",
    "def encode_emojis(text):\n",
    "    demojized = ej.demojize(text)\n",
    "    return re.sub(r':([^:]+):', lambda m: f\" emoji_{m.group(1)} \", demojized)\n",
    "\n",
    "def expand_abbreviations(text):\n",
    "    abbreviations = {\n",
    "        r'\\bimo\\b': 'in my opinion',\n",
    "        r'\\brt\\b': 'retweet',\n",
    "        r'\\bu\\b': 'you',\n",
    "        r'\\bur\\b': 'your',\n",
    "        r'\\bomg\\b': 'oh my god',\n",
    "        r'\\blmao\\b': 'laughing my ass off',\n",
    "        r'\\bidk\\b': 'i do not know',\n",
    "        r'\\bsmh\\b': 'shaking my head',\n",
    "        r'\\basap\\b': 'as soon as possible',\n",
    "        r'\\bdm\\b': 'direct message',\n",
    "        r'\\bbtw\\b': 'by the way',\n",
    "        r'\\btbh\\b': 'to be honest',\n",
    "        r'\\bfyi\\b': 'for your information'\n",
    "    }\n",
    "\n",
    "    for pattern, replacement in abbreviations.items():\n",
    "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def expand_contractions(text):\n",
    "    contractions = {\n",
    "        r\"\\bcan't\\b\": \"cannot\",\n",
    "        r\"\\bwon't\\b\": \"will not\",\n",
    "        r\"\\bi'm\\b\": \"i am\",\n",
    "        r\"\\bthey're\\b\": \"they are\",\n",
    "        r\"\\bwe're\\b\": \"we are\",\n",
    "        r\"\\byou're\\b\": \"you are\",\n",
    "        r\"\\bit's\\b\": \"it is\",\n",
    "        r\"\\bdon't\\b\": \"do not\",\n",
    "        r\"\\bdoesn't\\b\": \"does not\",\n",
    "        r\"\\bdidn't\\b\": \"did not\",\n",
    "        r\"\\bhasn't\\b\": \"has not\",\n",
    "        r\"\\bhaven't\\b\": \"have not\",\n",
    "        r\"\\bhadn't\\b\": \"had not\",\n",
    "        r\"\\bwouldn't\\b\": \"would not\",\n",
    "        r\"\\bcouldn't\\b\": \"could not\",\n",
    "        r\"\\bshouldn't\\b\": \"should not\",\n",
    "        r\"\\bi've\\b\": \"i have\",\n",
    "        r\"\\byou've\\b\": \"you have\",\n",
    "        r\"\\bthey've\\b\": \"they have\",\n",
    "        r\"\\bwho's\\b\": \"who is\",\n",
    "        r\"\\bwhat's\\b\": \"what is\",\n",
    "        r\"\\bthat's\\b\": \"that is\",\n",
    "        r\"\\blet's\\b\": \"let us\",\n",
    "        r\"\\bi'll\\b\": \"i will\",\n",
    "        r\"\\byou'll\\b\": \"you will\",\n",
    "        r\"\\bthey'll\\b\": \"they will\",\n",
    "        r\"\\bit'll\\b\": \"it will\",\n",
    "        r\"\\bthere's\\b\": \"there is\"\n",
    "    }\n",
    "\n",
    "    for pattern, replacement in contractions.items():\n",
    "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Final data cleaner function\n",
    "def clean_text(text):\n",
    "    text = encode_emojis(text) # Encode all emojis\n",
    "\n",
    "    text = encode_hashtags(text) # Encode all hashtags\n",
    "\n",
    "    text = encode_mentions(text) # Encode all mentions (@username)\n",
    "\n",
    "    text = expand_abbreviations(text) # Expand all abbreviations\n",
    "\n",
    "    text = expand_contractions(text) # Expand all contractions\n",
    "    \n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text) # Remove all URLs\n",
    "\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)  # Remove emails\n",
    "\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s\\.\\,\\!\\?_'’]\", '', text) # Keep apostrophes\n",
    "\n",
    "    text = re.sub(r'([.,!?_])', r' \\1 ', text) # Space out punctuation for clear tokenization:\n",
    "\n",
    "    text = text.lower() # Convert to lowercase\n",
    "\n",
    "    text = ' '.join(text.split()) # Remove extra whitespaces\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "59c27d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji as ej\n",
    "\n",
    "class TextCleaner:\n",
    "    def __init__(self, remove_profanity=False, preserve_quotes=True):\n",
    "        self.remove_profanity = remove_profanity\n",
    "        self.preserve_quotes = preserve_quotes\n",
    "\n",
    "        self.abbreviations = {\n",
    "            r'\\bimo\\b': 'in my opinion',\n",
    "            r'\\brt\\b': 'retweet',\n",
    "            r'\\bu\\b': 'you',\n",
    "            r'\\bur\\b': 'your',\n",
    "            r'\\bomg\\b': 'oh my god',\n",
    "            r'\\blmao\\b': 'laughing my ass off',\n",
    "            r'\\bidk\\b': 'i do not know',\n",
    "            r'\\bsmh\\b': 'shaking my head',\n",
    "            r'\\basap\\b': 'as soon as possible',\n",
    "            r'\\bdm\\b': 'direct message',\n",
    "            r'\\bbtw\\b': 'by the way',\n",
    "            r'\\btbh\\b': 'to be honest',\n",
    "            r'\\bfyi\\b': 'for your information'\n",
    "        }\n",
    "\n",
    "        self.contractions = {\n",
    "            r\"\\bcan't\\b\": \"cannot\",\n",
    "            r\"\\bwon't\\b\": \"will not\",\n",
    "            r\"\\bi'm\\b\": \"i am\",\n",
    "            r\"\\bthey're\\b\": \"they are\",\n",
    "            r\"\\bwe're\\b\": \"we are\",\n",
    "            r\"\\byou're\\b\": \"you are\",\n",
    "            r\"\\bit's\\b\": \"it is\",\n",
    "            r\"\\bdon't\\b\": \"do not\",\n",
    "            r\"\\bdoesn't\\b\": \"does not\",\n",
    "            r\"\\bdidn't\\b\": \"did not\",\n",
    "            r\"\\bhasn't\\b\": \"has not\",\n",
    "            r\"\\bhaven't\\b\": \"have not\",\n",
    "            r\"\\bhadn't\\b\": \"had not\",\n",
    "            r\"\\bwouldn't\\b\": \"would not\",\n",
    "            r\"\\bcouldn't\\b\": \"could not\",\n",
    "            r\"\\bshouldn't\\b\": \"should not\",\n",
    "            r\"\\bi've\\b\": \"i have\",\n",
    "            r\"\\byou've\\b\": \"you have\",\n",
    "            r\"\\bthey've\\b\": \"they have\",\n",
    "            r\"\\bwho's\\b\": \"who is\",\n",
    "            r\"\\bwhat's\\b\": \"what is\",\n",
    "            r\"\\bthat's\\b\": \"that is\",\n",
    "            r\"\\blet's\\b\": \"let us\",\n",
    "            r\"\\bi'll\\b\": \"i will\",\n",
    "            r\"\\byou'll\\b\": \"you will\",\n",
    "            r\"\\bthey'll\\b\": \"they will\",\n",
    "            r\"\\bit'll\\b\": \"it will\",\n",
    "            r\"\\bthere's\\b\": \"there is\"\n",
    "        }\n",
    "\n",
    "        self.profanity_list = [r'\\bshit\\b', r'\\bfuck\\b', r'\\bass\\b', r'\\bdamn\\b']  # Extend as needed\n",
    "\n",
    "    def encode_hashtags(self, text):\n",
    "        return re.sub(r'#(\\w+)', lambda m: f\" hashtag_{m.group(1)} \", text)\n",
    "\n",
    "    def encode_mentions(self, text):\n",
    "        return re.sub(r'@(\\w+)', lambda m: f\" mention_{m.group(1)} \", text)\n",
    "\n",
    "    def encode_emojis(self, text):\n",
    "        demojized = ej.demojize(text)\n",
    "        return re.sub(r':([^:]+):', lambda m: f\" emoji_{m.group(1)} \", demojized)\n",
    "\n",
    "    def expand_abbreviations(self, text):\n",
    "        for pattern, replacement in self.abbreviations.items():\n",
    "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "        return text\n",
    "\n",
    "    def expand_contractions(self, text):\n",
    "        for pattern, replacement in self.contractions.items():\n",
    "            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
    "        return text\n",
    "\n",
    "    def remove_noise(self, text):\n",
    "        text = re.sub(r'\\b(?:https?://|www\\.)\\S+\\b', '', text)\n",
    "        text = re.sub(r'\\S+@\\S+', '', text)  # Remove emails\n",
    "        return text\n",
    "\n",
    "    def remove_profanity_words(self, text):\n",
    "        for word in self.profanity_list:\n",
    "            text = re.sub(word, '[censored]', text, flags=re.IGNORECASE)\n",
    "        return text\n",
    "\n",
    "    def clean(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            return ''\n",
    "\n",
    "        text = self.encode_emojis(text)\n",
    "        text = self.encode_hashtags(text)\n",
    "        text = self.encode_mentions(text)\n",
    "        text = self.expand_abbreviations(text)\n",
    "        text = self.expand_contractions(text)\n",
    "        text = self.remove_noise(text)\n",
    "\n",
    "        # Base pattern\n",
    "        if self.preserve_quotes:\n",
    "            pattern = r\"[^a-zA-Z0-9\\s.,!?_'’\\\"]\"  # Preserve quotes\n",
    "        else:\n",
    "            pattern = r\"[^a-zA-Z0-9\\s.,!?_'’]\"    # Remove quotes\n",
    "\n",
    "        text = re.sub(pattern, '', text)\n",
    "\n",
    "        # Space out punctuation\n",
    "        if self.preserve_quotes:\n",
    "            text = re.sub(r'([.,!?_\"\\'])', r' \\1 ', text)\n",
    "        else:\n",
    "            text = re.sub(r'([.,!?_])', r' \\1 ', text)\n",
    "\n",
    "        if self.remove_profanity:\n",
    "            text = self.remove_profanity_words(text)\n",
    "\n",
    "        text = text.lower()\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2fec1863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep important columns and information\n",
    "columns_to_keep = ['clean_text', 'sentiment', 'event_type', 'event_type_detail', 'label'] \n",
    "datasets = [train_raw_data, test_raw_data, validation_raw_data]\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    datasets[i].dropna(inplace=True) # Remove missing values\n",
    "    datasets[i].rename(columns={'target': 'sentiment'}, inplace=True) # Rename column\n",
    "\n",
    "    # Clean text\n",
    "    cleaner = TextCleaner()\n",
    "    datasets[i]['clean_text'] = datasets[i]['text'].apply(cleaner.clean)\n",
    "\n",
    "    # Only keep columns that exist in both the dataframe and our columns_to_keep list\n",
    "    available_columns = [col for col in columns_to_keep if col in datasets[i].columns]\n",
    "    datasets[i] = datasets[i][available_columns]\n",
    "\n",
    "train_cleaned_data = datasets[0]\n",
    "test_cleaned_data = datasets[1]\n",
    "validation_cleaned_data = datasets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3ee26992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_type_detail</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>retweet mention _ violetposie emoji _ all of t...</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>target_zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>after china warns india , baloch and sindhi le...</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>informative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mention _ sollygc very but i managed to get a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>flood</td>\n",
       "      <td>flood</td>\n",
       "      <td>not_relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eastern and western attica declared in a state...</td>\n",
       "      <td>1</td>\n",
       "      <td>fire</td>\n",
       "      <td>wild_fire</td>\n",
       "      <td>caution_and_advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>let us all help those poor people in nepal . i...</td>\n",
       "      <td>1</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>relevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  sentiment  event_type  \\\n",
       "0  retweet mention _ violetposie emoji _ all of t...          0     unknown   \n",
       "1  after china warns india , baloch and sindhi le...          1     unknown   \n",
       "2  mention _ sollygc very but i managed to get a ...          0       flood   \n",
       "4  eastern and western attica declared in a state...          1        fire   \n",
       "5  let us all help those poor people in nepal . i...          1  earthquake   \n",
       "\n",
       "  event_type_detail               label  \n",
       "0           unknown         target_zero  \n",
       "1           unknown         informative  \n",
       "2             flood        not_relevant  \n",
       "4         wild_fire  caution_and_advice  \n",
       "5        earthquake            relevant  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect head of cleaned data\n",
    "train_cleaned_data.head()\n",
    "test_cleaned_data.head()\n",
    "validation_cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e90d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned data to hadr/data/processed\n",
    "datasets = {\n",
    "    'train.csv': train_cleaned_data,\n",
    "    'test.csv': test_cleaned_data,\n",
    "    'validation.csv': validation_cleaned_data,\n",
    "}\n",
    "\n",
    "for data in datasets:\n",
    "    file_path = os.path.join(project_root, 'data', 'processed', data)\n",
    "    datasets[data].to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
